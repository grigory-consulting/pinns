{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d43b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18cf1305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "x0: float = 1.0 \n",
    "t_min = 0.0\n",
    "t_max = 1.0 \n",
    "\n",
    "hidden_size = 16 # number of neurons \n",
    "lr = 0.1\n",
    "\n",
    "\n",
    "seed = 1 \n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,hidden_size = hidden_size , output_tanh = False):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            nn.Linear(1, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1), \n",
    "        ]\n",
    "        if output_tanh:\n",
    "            layers.append(nn.Tanh()) \n",
    "        \n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, t):\n",
    "        return self.mlp(t)\n",
    "    \n",
    "\n",
    "\n",
    "def choose_device(device = \"\"):\n",
    "    if device:\n",
    "        chosen = torch.device(device)\n",
    "        if chosen.type == \"mps\": # \n",
    "            raise ValueError(\"MPS does not support float64\")\n",
    "        return chosen\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def grad(outputs, inputs):\n",
    "    return torch.autograd.grad( # compute derivative of outputs w.r.t. inputs \n",
    "        outputs,\n",
    "        inputs,\n",
    "        grad_outputs=torch.ones_like(outputs), # vector Jacobian product\n",
    "        create_graph= True,  # because we will differentiate again \n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "def pde(x,t, omega): # your physical system\n",
    "    dxdt = grad(x,t) # first derivative\n",
    "    d2xdt2 = grad(dxdt, t) \n",
    "    return d2xdt2 +  (omega*omega)*x \n",
    "\n",
    "\n",
    "def model_loss(model_nn,t, x0_true , dx0dt_true, omega,bc_weight,  mse): # true initial value \n",
    "    x = model_nn(t) # neural network \n",
    "    f = pde(x,t,omega) # physical system \n",
    "\n",
    "    t0 = torch.zeros((1,1), dtype=t.dtype, device=t.device, requires_grad=True)\n",
    "    x0_pred = model_nn(t0) \n",
    "    dx0dt_pred = grad(x0_pred,t0)\n",
    "\n",
    "    loss_bc = mse(dx0dt_pred, dx0dt_true)\n",
    "    loss_ic = mse(x0_pred,x0_true)\n",
    "    loss_pde = mse(f, torch.zeros_like(f))\n",
    "\n",
    "    loss = loss_pde + bc_weight*(loss_bc + loss_ic) # in this particular case: bc_weight \n",
    "\n",
    "    x_true = x0_true*torch.cos(omega*t) # true solution \n",
    "    loss_data = mse(x, x_true)\n",
    "\n",
    "    metrics = {\n",
    "        \"loss_total\": float(loss.detach().cpu()),\n",
    "        \"loss_bc\": float(loss_bc.detach().cpu()),\n",
    "        \"loss_ic\": float(loss_ic.detach().cpu()),\n",
    "        \"loss_pde\": float(loss_pde.detach().cpu()),\n",
    "        \"loss_data\": float(loss_data.detach().cpu()),\n",
    "    }\n",
    "\n",
    "    return loss, metrics\n",
    "\n",
    "\n",
    "def train(model, device):\n",
    "    omega = 2.0 * torch.pi \n",
    "    mse = nn.MSELoss()\n",
    "    t = torch.linspace(t_min,t_max, 100, dtype=torch.float64, device=device,requires_grad=True).view(-1,1)\n",
    "    x0_true = torch.tensor([[x0]], dtype=torch.float64,device= device)\n",
    "    dx0dt_true = torch.zeros((1,1), dtype=torch.float64, device=device) # boundary condition \n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for step in range(1,1000 + 1):\n",
    "        optimizer.zero_grad() \n",
    "        loss_val, metrics = model_loss(\n",
    "            model_nn=model,\n",
    "            t=t,\n",
    "            x0_true=x0_true,\n",
    "            dx0dt_true=dx0dt_true,\n",
    "            omega=omega,\n",
    "            bc_weight=1000,\n",
    "            mse=mse\n",
    "        )\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step ==1 or step % 40 == 0:\n",
    "            print(metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a575c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss_total': 1669.023345413963, 'loss_bc': 0.00023518054132183432, 'loss_ic': 1.5711219567089207, 'loss_pde': 97.66620816372023, 'loss_data': 0.5736324862236907}\n",
      "{'loss_total': 261.8001415520049, 'loss_bc': 0.009121935391725964, 'loss_ic': 0.10905503133303293, 'loss_pde': 143.62317482724598, 'loss_data': 0.5304720550417436}\n",
      "{'loss_total': 1243.0685386318964, 'loss_bc': 0.0033509649797199585, 'loss_ic': 0.0005799169048668543, 'loss_pde': 1239.1376567473096, 'loss_data': 1.2705995265433279}\n",
      "{'loss_total': 681.0918693926845, 'loss_bc': 8.707520402343972e-08, 'loss_ic': 0.6245240692854183, 'loss_pde': 56.56771303206221, 'loss_data': 0.5172182276483784}\n",
      "{'loss_total': 540.8496569121605, 'loss_bc': 1.138474861201276e-08, 'loss_ic': 0.23245358659995366, 'loss_pde': 308.3960589274582, 'loss_data': 0.8250145759182536}\n",
      "{'loss_total': 613.7217283848116, 'loss_bc': 4.084500542225666e-18, 'loss_ic': 0.4243355775365602, 'loss_pde': 189.3861508482514, 'loss_data': 0.6195428805253418}\n",
      "{'loss_total': 609.2547157461737, 'loss_bc': 2.228562504416742e-18, 'loss_ic': 0.36342302493004713, 'loss_pde': 245.8316908161266, 'loss_data': 0.6547883958392778}\n",
      "{'loss_total': 609.1533653995334, 'loss_bc': 2.1984078137863836e-18, 'loss_ic': 0.3715665266448939, 'loss_pde': 237.58683875463953, 'loss_data': 0.6496326378065068}\n",
      "{'loss_total': 609.152937039475, 'loss_bc': 2.1966025032273974e-18, 'loss_ic': 0.3710435056926199, 'loss_pde': 238.10943134685513, 'loss_data': 0.6499593624111167}\n",
      "{'loss_total': 609.1529360613331, 'loss_bc': 2.1949295794658347e-18, 'loss_ic': 0.3710666193159557, 'loss_pde': 238.08631674537742, 'loss_data': 0.649944910978049}\n",
      "{'loss_total': 609.1529360634938, 'loss_bc': 2.1931614473368635e-18, 'loss_ic': 0.37106534832048244, 'loss_pde': 238.08758774301145, 'loss_data': 0.6499457056179976}\n",
      "{'loss_total': 609.1529360531763, 'loss_bc': 2.1912839088289826e-18, 'loss_ic': 0.37106719060674237, 'loss_pde': 238.08574544643395, 'loss_data': 0.649944553802623}\n",
      "{'loss_total': 609.1529360491375, 'loss_bc': 2.189300998564676e-18, 'loss_ic': 0.371067315310283, 'loss_pde': 238.0856207388545, 'loss_data': 0.649944475837239}\n",
      "{'loss_total': 609.1529360449028, 'loss_bc': 2.1872141517088227e-18, 'loss_ic': 0.37106729817380973, 'loss_pde': 238.08563787109307, 'loss_data': 0.6499444865513394}\n",
      "{'loss_total': 609.1529360404596, 'loss_bc': 2.1850249368017437e-18, 'loss_ic': 0.3710672953349361, 'loss_pde': 238.08564070552356, 'loss_data': 0.649944488326484}\n",
      "{'loss_total': 609.1529360358093, 'loss_bc': 2.1827346795908473e-18, 'loss_ic': 0.37106729479487466, 'loss_pde': 238.08564124093465, 'loss_data': 0.6499444886644057}\n",
      "{'loss_total': 609.1529360309536, 'loss_bc': 2.1803444519868405e-18, 'loss_ic': 0.3710672948436548, 'loss_pde': 238.08564118729876, 'loss_data': 0.6499444886341911}\n",
      "{'loss_total': 609.1529360258942, 'loss_bc': 2.177855115507672e-18, 'loss_ic': 0.37106729483446205, 'loss_pde': 238.08564119143216, 'loss_data': 0.6499444886402334}\n",
      "{'loss_total': 609.1529360206325, 'loss_bc': 2.1752673530854208e-18, 'loss_ic': 0.37106729483008494, 'loss_pde': 238.08564119054753, 'loss_data': 0.6499444886432768}\n",
      "{'loss_total': 609.1529360151686, 'loss_bc': 2.1725816946436642e-18, 'loss_ic': 0.37106729482659145, 'loss_pde': 238.08564118857714, 'loss_data': 0.6499444886457795}\n",
      "{'loss_total': 609.1529360095033, 'loss_bc': 2.169798537622872e-18, 'loss_ic': 0.37106729482284073, 'loss_pde': 238.08564118666257, 'loss_data': 0.6499444886484546}\n",
      "{'loss_total': 609.1529360036373, 'loss_bc': 2.166918163882064e-18, 'loss_ic': 0.3710672948189677, 'loss_pde': 238.08564118466958, 'loss_data': 0.649944488651218}\n",
      "{'loss_total': 609.1529359975697, 'loss_bc': 2.163940753692393e-18, 'loss_ic': 0.3710672948149627, 'loss_pde': 238.08564118260702, 'loss_data': 0.6499444886540754}\n",
      "{'loss_total': 609.1529359913008, 'loss_bc': 2.1608663975261044e-18, 'loss_ic': 0.37106729481082806, 'loss_pde': 238.08564118047266, 'loss_data': 0.6499444886570254}\n",
      "{'loss_total': 609.1529359848304, 'loss_bc': 2.1576951060224814e-18, 'loss_ic': 0.3710672948065566, 'loss_pde': 238.08564117827376, 'loss_data': 0.649944488660073}\n",
      "{'loss_total': 609.1529359781581, 'loss_bc': 2.1544268185429576e-18, 'loss_ic': 0.3710672948021551, 'loss_pde': 238.085641176003, 'loss_data': 0.6499444886632137}\n"
     ]
    }
   ],
   "source": [
    "device = choose_device(\"cpu\")\n",
    "torch.set_default_dtype(torch.float64)\n",
    "model = MLP().to(device)\n",
    "train(model,device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
