{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " TODOs (intentionally not implemented):\n",
    "- `build_training_data`\n",
    "- `class PINN`\n",
    "- `model_loss`\n",
    "- `train`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "376fea7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.17.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: numpy<2.7,>=1.26.4 in /Users/grigo/gits/seminars/it-schulungen.com/Siemens/Physics-Informed AI/src/harmonic_oscillator/.venv/lib/python3.12/site-packages (from scipy) (2.4.2)\n",
      "Downloading scipy-1.17.1-cp312-cp312-macosx_14_0_arm64.whl (20.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy\n",
      "Successfully installed scipy-1.17.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from scipy.integrate import quad\n",
    "\n",
    "\n",
    "def build_training_data(\n",
    "    num_bc: Tuple[int, int] = (25, 25),\n",
    "    num_ic: int = 50,\n",
    "    num_f: int = 10_000,\n",
    "    seed: int = 0,\n",
    "):\n",
    "    \"\"\"\n",
    "    TODO : Implement the training-data construction.\n",
    "\n",
    "    Target behavior (same as original script):\n",
    "    - Create BC samples for x=-1 and x=1, t in [0,1], u=0\n",
    "    - Create IC samples for t=0, x in [-1,1], u=-sin(pi x)\n",
    "    - Create interior collocation points (x,t) in (-1,1)x(0,1)\n",
    "    - Return: xf, tf, x0, t0, u0\n",
    "    \"\"\"\n",
    "\n",
    "    # u(-1, t) = 0 and u(1,t) = 0\n",
    "    t0_bc1 = torch.linspace(0.0, 1.0, num_bc[0]).view(-1,1)\n",
    "    t0_bc2 = torch.linspace(0.0, 1.0, num_bc[1]).view(-1,1)\n",
    "    x0_bc1 = -torch.ones(num_bc[0],1)\n",
    "    x0_bc2 = torch.ones(num_bc[1],1)\n",
    "    u0_bc1 = torch.zeros(num_bc[0], 1)\n",
    "    u0_bc2 = torch.zeros(num_bc[1], 1)\n",
    "\n",
    "    # Initial condition: u(x,0) = -sin(pi x) \n",
    "    x0_ic = torch.linspace(-1., 1., num_ic).view(-1,1)\n",
    "    t0_ic = torch.zeros(num_ic, 1)\n",
    "    u0_ic = - torch.sin(torch.pi * x0_ic)\n",
    "\n",
    "    x_bc = torch.cat([x0_bc1,x0_bc2], dim=0)\n",
    "    t_bc = torch.cat([t0_bc1,t0_bc2], dim=0)\n",
    "    u_bc = torch.cat([u0_bc1,u0_bc2], dim=0) \n",
    "    # put everything as a matrix together \n",
    "\n",
    "    # Interior collocation points in (x,t) in (-1, 1) x (0,1)\n",
    "\n",
    "    points = torch.rand(num_f, 2) # uniformly distributed from [0,1]\n",
    "    xf = 2.0 * points[:, 0:1] - 1.0\n",
    "    tf = points[:,1:2] \n",
    "\n",
    "    return xf, tf, x0_ic, t0_ic, u0_ic,x_bc, t_bc, u_bc \n",
    "\n",
    "    \n",
    "\n",
    "     \n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    raise NotImplementedError(\"TODO: implement build_training_data\")\n",
    "\n",
    "\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, in_dim: int = 2, hidden_dim: int = 16, num_hidden: int = 8, out_dim: int = 1):\n",
    "        super().__init__()\n",
    "        layers = [nn.Linear(in_dim, hidden_dim), nn.Tanh()]\n",
    "\n",
    "        for _ in range(num_hidden - 1):\n",
    "            layers += [nn.Linear(hidden_dim, hidden_dim), nn.Tanh()]\n",
    "        layers += [nn.Linear(hidden_dim, out_dim)]\n",
    "        self.pinn = nn.Sequential(*layers) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.pinn(x) \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "def grad(outputs, inputs):  # compute derivative of outputs w.r.t. inputs \n",
    "    return torch.autograd.grad( \n",
    "        outputs,\n",
    "        inputs,\n",
    "        grad_outputs=torch.ones_like(outputs), \n",
    "        create_graph= True,  \n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "def pde(u,x,t, nu ): \n",
    "    u_x = grad(u,x)\n",
    "    u_t = grad(u,t)\n",
    "    u_xx = grad(u_x, x)\n",
    "    f = u_t + u*u_x - nu*u_xx\n",
    "    return f\n",
    "\n",
    "def model_loss(\n",
    "        net: nn.Module, \n",
    "        xf: torch.Tensor, # input to PDE\n",
    "        tf: torch.Tensor, \n",
    "        x0: torch.Tensor, # IC\n",
    "        t0: torch.Tensor, \n",
    "        u0: torch.Tensor, \n",
    "        x_bc: torch.Tensor, # BC  \n",
    "        t_bc: torch.Tensor, \n",
    "        u_bc: torch.Tensor,  \n",
    "        mse ):\n",
    "    \"\"\"\n",
    "    TODO : Implement PINN loss.\n",
    "\n",
    "    \"\"\"\n",
    "    nu = .01 / torch.pi \n",
    "\n",
    "    x = xf.requires_grad_(True)\n",
    "    t = tf.requires_grad_(True)\n",
    "\n",
    "    u = net(torch.cat([x,t], dim = 1))\n",
    "\n",
    "    f = pde(u, x, t, nu) \n",
    "    mse_f = mse(f, torch.zeros_like(f))\n",
    "\n",
    "    u0_pred = net(torch.cat([x0, t0], dim=1))\n",
    "    mse_0 = mse(u0, u0_pred)\n",
    "\n",
    "    u_bc_pred = net(torch.cat([x_bc, t_bc], dim=1))\n",
    "    mse_bc = mse(u_bc, u_bc_pred) \n",
    "    loss = mse_f + mse_0 + mse_bc\n",
    "\n",
    "    return loss, mse_f , mse_0 , mse_bc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def solve_burgers(x: np.ndarray, t: float, nu: float) -> np.ndarray:\n",
    "    if t <= 0:\n",
    "        raise ValueError(\"t must be > 0 for this reference solution.\")\n",
    "\n",
    "    def f(y):\n",
    "        return np.exp(-np.cos(np.pi * y) / (2 * np.pi * nu))\n",
    "\n",
    "    def g(y):\n",
    "        return np.exp(-(y**2) / (4 * nu * t))\n",
    "\n",
    "    u = np.zeros_like(x, dtype=np.float64)\n",
    "    for i, xi in enumerate(x):\n",
    "        if abs(xi) != 1.0:\n",
    "            num_fun = lambda eta: np.sin(np.pi * (xi - eta)) * f(xi - eta) * g(eta)\n",
    "            den_fun = lambda eta: f(xi - eta) * g(eta)\n",
    "            num = -quad(num_fun, -np.inf, np.inf, limit=200)[0]\n",
    "            den = quad(den_fun, -np.inf, np.inf, limit=200)[0]\n",
    "            u[i] = num / den\n",
    "    return u\n",
    "\n",
    "\n",
    "def train():\n",
    "    \"\"\"\n",
    "    TODO: Implement training loop.\n",
    "    \"\"\"\n",
    "    torch.set_default_dtype(torch.float64)\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    xf, tf,  x_ic, t_ic, u_ic, x_bc, t_bc, u_bc = build_training_data()\n",
    "    xf, tf, x_ic, t_ic, u_ic, x_bc, t_bc, u_bc = [\n",
    "        z.to(device) for z in (xf, tf, x_ic, t_ic, u_ic, x_bc, t_bc, u_bc)\n",
    "    ]\n",
    "\n",
    "    net = PINN().to(device)\n",
    "\n",
    "    max_iterations = 1500 \n",
    "\n",
    "    mse = nn.MSELoss()\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(\n",
    "        net.parameters(),\n",
    "        lr = 0.1, \n",
    "        history_size=50, \n",
    "    )\n",
    "\n",
    "    for iteration in range(1, max_iterations +1 ):\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            loss,_ ,_ ,_ = model_loss(net, xf, tf, x_ic, t_ic, u_ic, x_bc, t_bc, u_bc,mse)\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        loss = optimizer.step(closure)\n",
    "\n",
    "        # from here classically \n",
    "        optimizer.zero_grad()\n",
    "        loss_value, mse_f, mse_ic, mse_bc = model_loss(net, xf, tf, x_ic, t_ic, u_ic, x_bc, t_bc, u_bc,mse)\n",
    "        loss_value.backward()\n",
    "\n",
    "        if iteration % 50 == 0 or iteration == 1:\n",
    "            print(\n",
    "                f\"iter={iteration:4d}  loss={loss_value.item():.6e}  \"\n",
    "                f\"mse_f={mse_f.item():.6e}  mse_ic={mse_ic.item():.6e}  mse_bc={mse_bc.item():.6e}  \"\n",
    "            )\n",
    "    \n",
    "    return net \n",
    "\n",
    "\n",
    "def evaluate(net: nn.Module):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    net.eval()\n",
    "    nu = 0.01 / math.pi\n",
    "\n",
    "    t_test = [0.25, 0.5, 0.75, 1.0]\n",
    "    x_test = np.linspace(-1.0, 1.0, 1001)\n",
    "\n",
    "    u_pred = []\n",
    "    u_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x_torch = torch.from_numpy(x_test).view(-1, 1)\n",
    "        for t in t_test:\n",
    "            t_torch = torch.full_like(x_torch, t)\n",
    "            xt = torch.cat([x_torch, t_torch], dim=1)\n",
    "            u_p = net(xt).cpu().numpy().reshape(-1)\n",
    "            u_t = solve_burgers(x_test, t, nu)\n",
    "            u_pred.append(u_p)\n",
    "            u_true.append(u_t)\n",
    "\n",
    "    u_pred = np.stack(u_pred, axis=0)\n",
    "    u_true = np.stack(u_true, axis=0)\n",
    "    err = np.linalg.norm(u_pred - u_true) / np.linalg.norm(u_true)\n",
    "    print(f\"Relative L2 error: {err:.4f}\")\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 7), constrained_layout=True)\n",
    "    axes = axes.ravel()\n",
    "    for i, t in enumerate(t_test):\n",
    "        axes[i].plot(x_test, u_pred[i], \"-\", lw=2, label=\"Prediction\")\n",
    "        axes[i].plot(x_test, u_true[i], \"--\", lw=2, label=\"Target\")\n",
    "        axes[i].set_ylim(-1.1, 1.1)\n",
    "        axes[i].set_xlabel(\"x\")\n",
    "        axes[i].set_ylabel(f\"u(x, {t})\")\n",
    "    axes[0].legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run after implementing all TODOs:\n",
    "model = train()\n",
    "evaluate(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
